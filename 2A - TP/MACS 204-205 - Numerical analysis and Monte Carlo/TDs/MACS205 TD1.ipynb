{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "633b97aa",
   "metadata": {},
   "source": [
    "# Numerical analysis: TP-1 - Arnaud Capitan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cbcb568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c945eaa",
   "metadata": {},
   "source": [
    "#### 1) Integers and floating point representations\n",
    "run the following cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6171e443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a is equal to [2] and its type is int32.\n"
     ]
    }
   ],
   "source": [
    "a = 2 * np.ones(1).astype(int)\n",
    "print(f\"a is equal to {a} and its type is {a.dtype}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "37ad1b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 ** 60 = [0]\n",
      "2 ** 61 = [0]\n",
      "2 ** 62 = [0]\n",
      "2 ** 63 = [0]\n",
      "2 ** 64 = [0]\n",
      "2 ** 65 = [0]\n",
      "2 ** 66 = [0]\n",
      "2 ** 67 = [0]\n",
      "\n",
      "2 ** 30 = [1073741824]\n",
      "2 ** 31 = [-2147483648]\n",
      "2 ** 32 = [0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(60, 68):\n",
    "    print(f\"2 ** {i} = {a ** i}\")\n",
    "\n",
    "\n",
    "print(f\"\\n2 ** {30} = {a ** 30}\")\n",
    "print(f\"2 ** {31} = {a ** 31}\")\n",
    "print(f\"2 ** {32} = {a ** 32}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac01966",
   "metadata": {},
   "source": [
    "**Q1.  Can you explain the observed behavior ?  Propose a way to fix this.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebee717",
   "metadata": {},
   "source": [
    "a is a int32 variable, which means it is stored in a 31 bits variable, with 1 bit for the sign.\n",
    "\n",
    "If we take a close look at the int class declaration, we see that there is a bit_length attribute to the int class, so we can guess that the size of our int is allocated dynamically according to the calculations done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c939e78",
   "metadata": {},
   "source": [
    "class int:\n",
    "    @overload\n",
    "    def __new__(cls, x: ConvertibleToInt = ..., /) -> Self: ...\n",
    "    @overload\n",
    "    def __new__(cls, x: str | bytes | bytearray, /, base: SupportsIndex) -> Self: ...\n",
    "    def as_integer_ratio(self) -> tuple[int, Literal[1]]: ...\n",
    "    @property\n",
    "    def real(self) -> int: ...\n",
    "    @property\n",
    "    def imag(self) -> Literal[0]: ...\n",
    "    @property\n",
    "    def numerator(self) -> int: ...\n",
    "    @property\n",
    "    def denominator(self) -> Literal[1]: ...\n",
    "    def conjugate(self) -> int: ...\n",
    "    def bit_length(self) -> int: ...\n",
    "    if sys.version_info >= (3, 10):\n",
    "        def bit_count(self) -> int: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "47bf52ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a is equal to 2 and its type is <class 'int'>.\n",
      "2 ** 60 = 1152921504606846976\n",
      "2 ** 61 = 2305843009213693952\n",
      "2 ** 62 = 4611686018427387904\n",
      "2 ** 63 = 9223372036854775808\n",
      "2 ** 64 = 18446744073709551616\n",
      "2 ** 65 = 36893488147419103232\n",
      "2 ** 66 = 73786976294838206464\n",
      "2 ** 67 = 147573952589676412928\n"
     ]
    }
   ],
   "source": [
    "a = 2\n",
    "print(f\"a is equal to {a} and its type is {type(a)}.\")\n",
    "for i in range(60, 68):\n",
    "    print(f\"2 ** {i} = {a ** i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae02a39a",
   "metadata": {},
   "source": [
    "**Q2. Does the problem occur without specifying the dtype `np.ones(1)`? Deduce a real numpy usecase where this might be a problem.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e220da",
   "metadata": {},
   "source": [
    "This problem doesn't occur when we don't specify the dtype np.ones(1). It means that the numpy variables inside an array can't exceed 2**31.\n",
    "It might be an issue when computing in an array the **Mersennes** numbers in an array\n",
    "\n",
    "$$ M_n = 2^n - 1 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574334e9",
   "metadata": {},
   "source": [
    " In deep learning applications, chosing the \"right\" dtype is a very important tradeoff between speed and accuracy.\n",
    "\n",
    " ___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7540a340",
   "metadata": {},
   "source": [
    "#### 2) Imperfect floating point numbers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b8c4ad",
   "metadata": {},
   "source": [
    "Consider the function $f(x) = 2x$ on $[0, 0.5]$ and $f(x) = 2x - 1$ on $]0.5, 1]$ \n",
    "\n",
    "**Q1.** Consider the sequence defined by $x_{n+1} = f(x_n)$ with $x_0 = 0.1$ Compute the first 5 elements of the sequence (manually). What do you conclude ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b541c34d",
   "metadata": {},
   "source": [
    "$$ x_1 = 2*x_0 = 0.2 \\text{ because } x_0 \\in [0,0.5] $$ \n",
    "$$ x_2 = 2*x_1 = 0.4 \\text{ because } x_1 \\in [0,0.5] $$\n",
    "$$ x_3 = 2*x_2 = 0.8 \\text{ because } x_2 \\in [0,0.5] $$\n",
    "$$ x_4 = 2*x_3 - 1 = 0.6 \\text{ because } x_3 \\in ]0.5,1] $$\n",
    "$$ x_5 = 2*x_4 - 1 = 0.2 = x_1 \\text{ because } x_4 \\in ]0.5,1] $$ \n",
    "\n",
    "We can conclude that with $x_0 = 0.1$, the sequence $(x_n)$ defined by $x_{n+1} = f(x_n)$ is periodical, and we have, $\\forall n$ in $\\textbf{N}$ :\n",
    "\n",
    "$$ x_{4n+1} = 0.2 $$\n",
    "$$ x_{4n+2} = 0.4 $$\n",
    "$$ x_{4n+3} = 0.8 $$\n",
    "$$ x_{4n+4} = 0.6 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703140fd",
   "metadata": {},
   "source": [
    "**Q2.** Complete the function below that returns $x_n$. What do you observe ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bdcc7d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8125\n",
      "0.625\n",
      "0.25\n",
      "0.5\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "x0 = 0.1\n",
    "\n",
    "def f(x, n=100):\n",
    "    i = 0\n",
    "    while i < n :\n",
    "        i+=1\n",
    "        if x <= 0.5:\n",
    "            x = 2*x\n",
    "        else :\n",
    "            x = 2*x - 1\n",
    "    return x\n",
    "\n",
    "print(f(x0, 51))\n",
    "print(f(x0, 52))\n",
    "print(f(x0, 53))\n",
    "print(f(x0, 54))\n",
    "\n",
    "print(f(x0,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235b4a41",
   "metadata": {},
   "source": [
    "By using the computations done above the python function, we have that $f^{100}(x_0) = x_{100} = x_{24*4 + 4} = 0.6$\n",
    "\n",
    "But using python calculations, the integer approximation error grows so big that the calculation at around n = 50 are going around the fix point 0.5 -> 1 -> 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b37811e",
   "metadata": {},
   "source": [
    "`float64` numbers are represented using 64 bits as:\n",
    "$$(-1)^s \\quad 0.m_1..m_{52} \\quad 2^{e_1..e_{11}}$$\n",
    "where $s$ is a sign bit, $m$ is the mantissa (52 bits) and $e$ is the exponent (11 bits)\n",
    "\n",
    "**Q4** Take a moment a contemplate this mystery. Use the `pretty_float_bits` function below to find an explanation for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7363c071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30000000000000004"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.1 + 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3f833b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0 01111111011 1001100110011001100110011001100110011001100110011010'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import struct\n",
    "\n",
    "def float_to_bin(f) -> str:\n",
    "    fmt = \">d\"\n",
    "    bz = struct.pack(fmt, f)\n",
    "    return \"\".join(f\"{b:08b}\" for b in bz)\n",
    "\n",
    "def sign_exponent_fraction(s):\n",
    "    return s[0:1], s[1:12], s[12:64]\n",
    "\n",
    "def pretty_float_bits(f) -> str:\n",
    "    return \" \".join(sign_exponent_fraction(float_to_bin(f)))\n",
    "\n",
    "pretty_float_bits(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5c26306b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0 01111111101 0011001100110011001100110011001100110011001100110100'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretty_float_bits(0.1 + 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fc455468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0 01111111101 0011001100110011001100110011001100110011001100110011'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretty_float_bits(0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da88dae4",
   "metadata": {},
   "source": [
    "With floats, the order matters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ddd92c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100. - 100. + 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cb985cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09999999999999432"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.1 + 100. - 100."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a2ea5f",
   "metadata": {},
   "source": [
    "The mantissa of 0.1 + 0.2 and 0.3 are not the same because of the propagation of an error bit at the end of the mantissa, since the computer has to register ints of 32 bits. Thus the error when doing 0.1 + 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517bb030",
   "metadata": {},
   "source": [
    "#### 3) Machine precision and cumulative errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eeaccf4",
   "metadata": {},
   "source": [
    "Consider the integral $$I_n = \\int_{0}^1 \\frac{x^n}{x + 10}dx$$\n",
    "\n",
    "1. Without computing $I_n$, find its limit.\n",
    "2. Compute $I_0$ and find a recurrence formula between $I_{n+1}$ and $I_n$\n",
    "3. If we were to compute $I_n$ recursively, would that algorithm be stable numerically ?\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5f535a",
   "metadata": {},
   "source": [
    "1] We have :\n",
    "$$I_n = \\int_{0}^1 \\frac{x^n}{x + 10}dx \\leq \\int_{0}^1 \\frac{x^n}{10}dx = \\frac{1}{10(n+1)} $$ \n",
    "$$\\lim_{n \\to \\infty} I_n = 0$$\n",
    "\n",
    "2] $$I_0 = \\ln(11/10)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71df72d5",
   "metadata": {},
   "source": [
    "We compute the integral with a parameter $a > 1$\n",
    "For the computations in this part, we assume a = 10, and  $n \\geq 1$.\n",
    "$$I_{n+1} = \\int_{0}^1 \\frac{x^{n+1}}{x + a}dx$$\n",
    "\n",
    "We integrate by parts :\n",
    "\n",
    "$$\\int_{0}^1 \\frac{x^{n+1}}{x + a}dx = [x^{n+1}\\ln(x+a)]_0^1 - \\int_{0}^1 (n+1)x^n\\ln(x+a) dx$$\n",
    "\n",
    "$$I_{n+1} = \\ln(a+1) - (n+1)\\int_{0}^1 x^n\\ln(x+a) dx$$\n",
    "\n",
    "We want to compute $\\int_{0}^1 x^n\\ln(x+a) dx$. We integrate by parts :\n",
    "\n",
    "$$\\int_{0}^1 x^n\\ln(x+a) dx = [x^n(x+a)(\\ln(x+a)-1)]_0^1 - \\int_{0}^1 nx^{n-1}(x+a)(\\ln(x+a)-1) dx$$\n",
    "\n",
    "$$\\int_{0}^1 x^n\\ln(x+a) dx = (1+a)(\\ln(1+a)-1) - n\\int_{0}^1 x^{n-1}(x+a)(\\ln(x+a)-1) dx$$\n",
    "\n",
    "$$I_{n+1} = \\ln(a+1) - (n+1)(1+a)(\\ln(1+a)-1) + n(n+1)\\int_{0}^1 x^{n-1}(x+a)(\\ln(x+a)-1) dx$$\n",
    "\n",
    "Since we have, $\\forall n \\geq 1$, $I_{n} = \\ln(a+1) - n\\int_{0}^1 x^{n-1}\\ln(x+a) dx$\n",
    "\n",
    "$$n(n+1)\\int_{0}^1 x^{n-1}(x+a)(\\ln(x+a)-1) dx = n(n+1)\\int_{0}^1 x^n(\\ln(x+a)-1) dx + an(n+1)\\int_{0}^1 x^{n-1}(\\ln(x+a)-1) dx $$\n",
    "$$n(n+1)\\int_{0}^1 x^{n-1}(x+a)(\\ln(x+a)-1) dx = n(n+1)\\int_{0}^1 x^n\\ln(x+a) dx - n(n+1)\\int_{0}^1 x^n dx + an(n+1)\\int_{0}^1 x^{n-1}\\ln(x+a) dx - an(n+1)\\int_{0}^1 x^{n-1} dx $$\n",
    "\n",
    "$$n(n+1)\\int_{0}^1 x^{n-1}(x+a)(\\ln(x+a)-1) dx = n(\\ln(1+a)-I_{n+1}) - n + a(n+1)(\\ln(1+a)-I_{n}) - a(n+1)$$\n",
    "\n",
    "Thus :\n",
    "\n",
    "$$I_{n+1} = \\ln(a+1) - (n+1)(1+a)(\\ln(1+a)-1) + n(\\ln(a+1)-I_{n+1}) - n + a(n+1)(\\ln(1+a)-I_{n}) - a(n+1)$$\n",
    "$$I_{n+1}(n+1) = \\ln(a+1) - (n+1)(1+a)(\\ln(1+a)-1) + n\\ln(1+a) - n + a(n+1)(\\ln(1+a)-I_{n}) - a(n+1)$$\n",
    "$$I_{n+1}(n+1) = \\ln(a+1) - (n+1)(1+a)\\ln(1+a) + (n+1)(1+a) + n\\ln(a+1) - n + a(n+1)\\ln(1+a)-a(n+1)I_{n} - a(n+1)$$\n",
    "\n",
    "$$I_{n+1}(n+1) = 1 - a(n+1)I_{n} + \\ln(1+a) - (n+1)(1+a)\\ln(1+a) + n\\ln(1+a) + a(n+1)\\ln(1+a)$$\n",
    "\n",
    "$$I_{n+1} = \\frac{1}{n+1} - aI_{n}$$\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a04a1b",
   "metadata": {},
   "source": [
    "Another way of obtaining this result is the following :\n",
    "\n",
    "$$I_{n+1} = \\int_{0}^1 \\frac{x^{n+1}}{x + a}dx$$\n",
    "\n",
    "$$I_{n+1} = \\int_{0}^1 \\frac{x^n(x+a) - ax^n}{x + a}dx$$\n",
    "\n",
    "$$I_{n+1} = \\int_{0}^1 x^n dx  - a \\int_{0}^1 \\frac{x^n}{x + a}dx$$\n",
    "\n",
    "$$I_{n+1} = \\frac{1}{n+1}  - a I_n$$\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b32426ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integral(i0, n):\n",
    "    ii = i0\n",
    "    for jj in range(n):\n",
    "        ii = 1/(jj+1) - 10*ii\n",
    "    return ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e39b02fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0 = 0.09531017980432493\n",
      "I1 = 0.04689820195675065\n",
      "I2 = 0.031017980432493486\n",
      "I3 = 0.023153529008398455\n",
      "I4 = 0.018464709916015454\n",
      "I5 = 0.015352900839845474\n",
      "I6 = 0.013137658268211921\n",
      "I7 = 0.011480560175023635\n",
      "I8 = 0.010194398249763648\n",
      "I9 = 0.009167128613474629\n",
      "I10 = 0.008328713865253717\n",
      "I11 = 0.007621952256553738\n",
      "I12 = 0.00711381076779595\n",
      "I13 = 0.005784969245117427\n",
      "I14 = 0.013578878977397152\n",
      "I15 = -0.06912212310730485\n",
      "I16 = 0.7537212310730486\n",
      "I17 = -7.478388781318721\n",
      "I18 = 74.83944336874276\n",
      "I19 = -748.3418021084802\n"
     ]
    }
   ],
   "source": [
    "for k in range(20):\n",
    "    print(f\"I{k} = {integral(np.log(11/10), k)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39632f2",
   "metadata": {},
   "source": [
    "4. Replace 10 in the integral with a constant A > 1. Given a machine precision variable $\\varepsilon$, how can we set the number of iterations $n$ based on a desired cumulative error E ?\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72889152",
   "metadata": {},
   "source": [
    "We consider a machine precision variable $\\varepsilon > 0$. That means that :\n",
    "\n",
    "$$|I_1 - (\\frac{1}{2} - AI_0)| = \\varepsilon$$\n",
    "\n",
    "We can write it as :\n",
    "\n",
    "$$ \\frac{1}{2} - AI_0 - \\varepsilon \\leq I_1 \\leq \\frac{1}{2} - AI_0 + \\varepsilon $$\n",
    "\n",
    "We apply the recurrence formula on this equality :\n",
    "\n",
    "$$ \\frac{1}{3} - A(\\frac{1}{2} - AI_0 + \\varepsilon) \\leq I_2 \\leq \\frac{1}{3} - A(\\frac{1}{2} - AI_0 - \\varepsilon) $$\n",
    "\n",
    "We add the machine precision variable for those calculations :\n",
    "\n",
    "$$ \\frac{1}{3} - A(\\frac{1}{2} - AI_0 + \\varepsilon) - \\varepsilon \\leq I_2 \\leq \\frac{1}{3} - A(\\frac{1}{2} - AI_0 - \\varepsilon) + \\varepsilon $$\n",
    "\n",
    "And we simplify to express $I_2$ with I_1 and the error.\n",
    "\n",
    "$$ \\frac{1}{3} - AI_1  - (A+1)\\varepsilon \\leq I_2 \\leq \\frac{1}{3} - AI_1 + (A+1)\\varepsilon $$\n",
    "\n",
    "We can then show recursively (on this model) that the cumulative error $E_n$ to compute $I_n$ can be expressed as follows :\n",
    "\n",
    "$$ E_n = \\varepsilon \\sum_{k=0}^{n-1} A^k $$\n",
    "\n",
    "We want to find $n$ such that $E_{n+1} \\geq E \\geq E_n$, which means that the number of iterations $n$ is based on the desired cumulative error E.\n",
    "\n",
    "$$ E_n \\leq E $$\n",
    "\n",
    "$$ \\varepsilon \\sum_{k=0}^{n-1} A^k \\leq E $$\n",
    "\n",
    "We recognize a finite geometric sum (the formula works $\\forall A \\in \\textbf{R}^*$ as long as the sum is finite) :\n",
    "\n",
    "$$ \\frac{1-A^n}{1-A} \\leq \\frac{E}{\\varepsilon} $$\n",
    "\n",
    "$$ \\frac{A^n-1}{A-1} \\leq \\frac{E}{\\varepsilon} $$\n",
    "\n",
    "$$ A^n \\leq \\frac{(A-1)E}{\\varepsilon} + 1 $$\n",
    "\n",
    "We take the natural logarithm which is an increasing function on $\\textbf{R}_+^*$ :\n",
    "\n",
    "$$ n \\leq \\frac{\\ln(\\frac{(A-1)E}{\\varepsilon} + 1)}{\\ln(A)} $$\n",
    "\n",
    "$$ n = \\left\\lfloor  \\frac{\\ln(\\frac{(A-1)E}{\\varepsilon} + 1)}{\\ln(A)} \\right\\rfloor $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd09b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.0\n"
     ]
    }
   ],
   "source": [
    "A = 10\n",
    "E = 0.001\n",
    "n = np.floor(np.log((A-1)*E/np.finfo(float).eps + 1)/np.log(A))\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7260d430",
   "metadata": {},
   "source": [
    "If A = 10, and the cumulative error must not exceed 0.001, then the max number of iterations is 13 before the cumulative error exceed E."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1c131b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.220446049250313e-16\n"
     ]
    }
   ],
   "source": [
    "print(np.finfo(float).eps) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb283da",
   "metadata": {},
   "source": [
    "**Independent questions:**\n",
    "\n",
    "**Q5.** Write a piece of code that can find $\\varepsilon$ numerically. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "26e5f4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.220446049250313e-16\n"
     ]
    }
   ],
   "source": [
    "eps = 1.0\n",
    "while 1.0 + eps != 1.0 :\n",
    "    eps /= 2 # We use power of two since the machine errors is stored using bits\n",
    "eps *= 2 # We want the last value of epsilon before epsilon is considered null by machine approximation\n",
    "print(eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a16719",
   "metadata": {},
   "source": [
    "We get the same value as the function np.finfo(float).eps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117bca24",
   "metadata": {},
   "source": [
    "**Q6.** Given what you know now, how should you test if two numbers or arrays are equal ? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3367fe56",
   "metadata": {},
   "source": [
    "Two numbers a and b are equal numerically if and only if $|a-b| \\leq \\varepsilon$  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbaf2de",
   "metadata": {},
   "source": [
    "#### 4) Logsum-exp trick\n",
    "Consider a classification model with 4 classes. We are modeling the probablity of a sample being in class $k$ with: $$p_k = \\frac{ exp(w_k)}{\\sum_{i=1}^{4} exp(w_i)}$$\n",
    "\n",
    "where $w$ are the weights of a neural net.\n",
    "1. Why does this model make sense ? \n",
    "2. Given the example $w = [-20, -1, 0, 1000]$, it is obvious which class this sample should correspond to. Compute the prediction probabilities using the function below for this particular example. Explain.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274fb4c8",
   "metadata": {},
   "source": [
    "1. This model makes sense because p is a probability, as $\\sum_{k=1}^{4} p_k = \\sum_{k=1}^{4} \\frac{ exp(w_k)}{\\sum_{i=1}^{4} exp(w_i)} = 1$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3e9f6b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnaud\\AppData\\Local\\Temp\\ipykernel_24284\\437721929.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  p = np.exp(w)\n",
      "C:\\Users\\Arnaud\\AppData\\Local\\Temp\\ipykernel_24284\\437721929.py:3: RuntimeWarning: invalid value encountered in divide\n",
      "  p /= p.sum()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0., nan])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(w):\n",
    "    p = np.exp(w)\n",
    "    p /= p.sum()\n",
    "    return p\n",
    "\n",
    "w = np.array([10, -1, 40, 2, 1000])\n",
    "predict(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692e966f",
   "metadata": {},
   "source": [
    "We have an overflow error, as $e^{1000}$ cannot be stored in a 32 bits float."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d025fd",
   "metadata": {},
   "source": [
    "3. Even if we assume that $exp(w_k)$ do not overflow, computing the normalizing sum can cause problems if the number of labels is too large. After showing the following statement, propose a method to modify `predict` in order to avoid overflow errors:\n",
    "$$ \\forall cÂ \\in \\mathbb{R} \\qquad log\\left(\\sum_{k=1}^K exp(w_k + c)\\right) =  c + log\\left(\\sum_{k=1}^K exp(w_k)\\right) $$ \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5e0ad5",
   "metadata": {},
   "source": [
    "What we can do it use the above trick with $ c = - max_{k \\in \\textbf{N}} (w_k)$ to normalize all coefficients and remove the overflow possibility, since all the values will be stricly inferior to 1 after rescaling, and the final model will remain the same after the shift.\n",
    "\n",
    "If we denote $ w = \\max _{k \\in \\textbf{N}} w_k $ :\n",
    "\n",
    "$$p_k = \\frac{ \\exp(w_k)}{\\sum_{i=1}^{4} \\exp(w_i)}$$\n",
    "\n",
    "$$p_k = \\frac{ \\exp(w_k - w)}{\\sum_{i=1}^{4} \\exp(w_i - w)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d41dffa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_stable(w):\n",
    "    w_scaled = w - np.max(w)\n",
    "    return (np.exp(w_scaled)/(np.sum(np.exp(w_scaled))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "98c93ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_stable(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59d8043",
   "metadata": {},
   "source": [
    "4. Generate random weight vectors with `np.random.randn(K)` and test that both functions return the same probabilities. Test it with the scipy `logsumexp`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "cecf62ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random vector : [-0.80173116 -2.69293807  2.40773644 -1.96127722 -1.51013622  0.20341492\n",
      " -0.56683723  1.81581674 -0.66458307 -0.88107965]\n",
      "Predict function result : [0.02150874 0.00324545 0.53268328 0.00674575 0.01059153 0.05876847\n",
      " 0.02720371 0.29471457 0.02467048 0.01986801]\n",
      "Predict stable function result : [0.02150874 0.00324545 0.53268328 0.00674575 0.01059153 0.05876847\n",
      " 0.02720371 0.29471457 0.02467048 0.01986801]\n"
     ]
    }
   ],
   "source": [
    "K = 10\n",
    "vect = np.random.randn(K)\n",
    "print(f\"Random vector : {vect}\")\n",
    "print(f\"Predict function result : {predict(vect)}\")\n",
    "print(f\"Predict stable function result : {predict_stable(vect)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b74e9c3",
   "metadata": {},
   "source": [
    "The results are the same."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
